# -*- coding: utf-8 -*-
"""modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rtp45VjFVfso2ZOFsF--lnA_gsPJ0syx

Load and Split Data
"""

from sklearn.model_selection import train_test_split
import pandas as pd

# Load filtered dataset (only "bully" and "not bully")
df_filtered = pd.read_csv("/content/drive/My Drive/TW/Dataset/collection/filtered_labeled_tweets.csv")

# Split into train (80%) and test (20%) sets
X_train, X_test, y_train, y_test = train_test_split(
    df_filtered["Text"], df_filtered["Label"], test_size=0.2, random_state=42, stratify=df_filtered["Label"]
)

print(f"âœ… Training size: {len(X_train)}, Testing size: {len(X_test)}")

"""Train the Model (TF-IDF + Logistic Regression)"""

from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

# Define TF-IDF + Logistic Regression model
clf = Pipeline([
    ("tfidf", TfidfVectorizer(max_features=5000)),
    ("lr", LogisticRegression())
])

# Train the model
clf.fit(X_train, y_train)
print("âœ… Model training complete!")

"""Evaluate the Model"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions
y_pred = clf.predict(X_test)

# Print accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"ðŸ”¥ Model Accuracy: {accuracy:.4f}")

# Print detailed classification report (precision, recall, F1-score)
print("\nðŸ“Š Classification Report:\n", classification_report(y_test, y_pred))

# Confusion matrix visualization
cm = confusion_matrix(y_test, y_pred, labels=["bully", "not bully"])
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["bully", "not bully"], yticklabels=["bully", "not bully"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""**code for gpu connectivity**"""

import torch

# Check if GPU is available
print("GPU Available:", torch.cuda.is_available())

# Print GPU details
if torch.cuda.is_available():
    print("GPU Name:", torch.cuda.get_device_name(0))
    print("GPU Count:", torch.cuda.device_count())

import tensorflow as tf

# Check if TensorFlow is using GPU
print("TensorFlow GPU:", tf.config.list_physical_devices('GPU'))

with tf.device('/GPU:0'):
    tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])
    print("Tensor on GPU:", tensor)

import torch

# Move a tensor to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
tensor = torch.tensor([1.0, 2.0, 3.0]).to(device)
print("Tensor on GPU:", tensor)

# Move tensor to GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
tensor = torch.rand(3, 3).to(device)

print("Tensor on:", device)  # It should print "cuda"

"""**Bert FineTune model**"""

import torch
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments

def preprocess_data(df_filtered):
    df_filtered = df_filtered[df_filtered["Label"].isin(["bully", "not bully"])]  # Use only labeled data
    df_filtered["Label"] = df_filtered["Label"].map({"bully": 1, "not bully": 0})
    return df_filtered

df_filtered=pd.read_csv("/content/drive/My Drive/project/filtered_labeled_tweets.csv")

df = preprocess_data(df_filtered)

from google.colab import drive
drive.mount('/content/drive')

# Split Data
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df["Translated_Text"].tolist(), df["Label"].tolist(), test_size=0.2, random_state=42
)

#Convert Text Data into Tokenized Format
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Tokenizing text
train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)
val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)

!pip install datasets

import torch
from datasets import Dataset

# Convert dictionary of tokenized encodings into a Dataset
train_dataset = Dataset.from_dict({
    "input_ids": train_encodings["input_ids"],
    "attention_mask": train_encodings["attention_mask"],
    "label": train_labels
})

val_dataset = Dataset.from_dict({
    "input_ids": val_encodings["input_ids"],
    "attention_mask": val_encodings["attention_mask"],
    "label": val_labels
})

# Load BERT Model
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

from transformers import EarlyStoppingCallback

!pip install evaluate
import evaluate

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = logits.argmax(axis=-1)  # Get class with highest probability
    accuracy_metric = evaluate.load("accuracy")
    return accuracy_metric.compute(predictions=predictions, references=labels)

training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",  # Evaluate at the end of every epoch
    save_strategy="epoch",  # Save model at the end of each epoch
    load_best_model_at_end=True,  # âœ… Required for EarlyStoppingCallback
    metric_for_best_model="accuracy",  # You can change this to another metric like "f1"
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=5,
    logging_dir="./logs",
    fp16=True,


)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] , # Early stopping after 3 epochs without improvement
    compute_metrics=compute_metrics
)

print(device)  # Should print 'cuda' if running on GPU
print(next(model.parameters()).device)  # Should print 'cuda:0'

import os
os.environ["WANDB_DISABLED"] = "true"

# Train Model
trainer.train()



# Save Model
model.save_pretrained("./fine_tuned_bert")
tokenizer.save_pretrained("./fine_tuned_bert")

# Evaluation
trainer.evaluate()

"""Label the "unsure" dataset"""

# Load unsure dataset
df_unsure = pd.read_csv("/content/drive/My Drive/project/unsure_labeled_tweets.csv")

unsure_texts=df_unsure['Translated_Text'].tolist()

# Tokenize unsure dataset
unsure_encodings = tokenizer(unsure_texts, truncation=True, padding=True, max_length=512, return_tensors="pt")
unsure_encodings = {key: val.to(device) for key, val in unsure_encodings.items()}  # Move to GPU if available

import numpy as np

from torch.utils.data import DataLoader, TensorDataset

# Convert encodings to PyTorch dataset
dataset = TensorDataset(unsure_encodings["input_ids"], unsure_encodings["attention_mask"])

# Define DataLoader with batch size
batch_size = 16  # Adjust based on your GPU memory
dataloader = DataLoader(dataset, batch_size=batch_size)

# Run inference in batches
model.eval()
predictions = []
with torch.no_grad():
    for batch in dataloader:
        input_ids, attention_mask = batch
        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)

        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        preds = torch.argmax(outputs.logits, dim=-1)
        predictions.extend(preds.cpu().numpy())  # Move results to CPU to save GPU memory

# Convert predictions to numpy array
predictions = np.array(predictions)

label_mapping = {0: "not bully", 1: "bully"}
predicted_labels = [label_mapping[label] for label in predictions]  # No need for .cpu().numpy()

# Save labeled dataset
df_unsure["predicted_label"] = predicted_labels

df_unsure.columns

df_unsure=df_unsure.drop(columns=['Label']) #deleting the labels column from unsure dataset since its values are unsure.

df_unsure=df_unsure.rename(columns={'predicted_label':'Label'})

df_unsure.to_csv("/content/drive/My Drive/project/relabelled_unsure_dataset.csv", index=False)

print("Relabeled unsure dataset saved successfully!")

df_unsure['Label'].value_counts()

"""Merge the unsure dataset after labeling with filtered labeled dataset."""

# Load the original dataset (assuming it's in CSV format)
df_original = pd.read_csv("/content/drive/My Drive/project/filtered_labeled_tweets.csv")  # Change filename if needed

# Merge both datasets
df_final = pd.concat([df_original, df_unsure], ignore_index=True)

# Save the merged dataset
df_final.to_csv("/content/drive/My Drive/project/final_training_dataset.csv", index=False)
print("Final dataset saved! Ready for training. ðŸš€")

df_final['Label'].value_counts()

"""**Retrain the Model with the Updated Dataset**"""

# Load new dataset
# Extract text and labels
texts = df_final["Translated_Text"].tolist()
labels = df_final["Label"].apply(lambda x: 1 if x == "Bully" else 0).tolist()  # Convert to binary labels

# Tokenization
encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors="pt")

# Train the model again
trainer.train()

